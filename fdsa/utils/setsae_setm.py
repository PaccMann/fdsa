from typing import Tuple

import torch
import torch.nn.functional as F
import torch.nn as nn
from fdsa.models.set_matching.rnn import RNNSetMatching
from fdsa.models.set_matching.seq2seq import Seq2Seq


class NetworkMapperSetsAE(nn.Module):
    """Pre-Trained Network as a Mapper for Sets AutoEncoder."""

    def __init__(
        self,
        model: str,
        model_path: str,
        params: dict,
        device: torch.device = torch.
        device('cuda' if torch.cuda.is_available() else 'cpu'),
        connector_value: float = 99.0,
    ) -> None:
        """Loads and initialises model to match two given sets.

        Args:
            model (str): String value indicating the architecture style of the
                matching network. One of 'rnn' or 'seq2seq'.
            model_path (str): Path to where the pre-trained matching network
                is saved.
            params (dict): Parameters necessary to initialise the matching
                network. This should be the same parameters used during the
                pre-training of the model.
            device (torch.device): Whether to run model on GPU or CPU.
                Defaults to CPU.
            connector_value (float, optional): Constant tensor of shape
                [batch size, 1, input size] that connects the two sets to be
                matched. Defaults to 99.0.
        """
        super(NetworkMapperSetsAE, self).__init__()

        model_dict = {'seq2seq': Seq2Seq, 'rnn': RNNSetMatching}
        self.padding_value = params.get('padding_value', 4.0)
        self.batch_first = eval(params.get('batch_first', 'False'))
        self.device = device
        self.connector = torch.full(
            (1, params.get('input_size', 128)), connector_value
        ).to(device)
        self.model = model
        self.mapper = model_dict[model](params, device).to(device)

        checkpoint = torch.load(model_path)
        self.mapper.load_state_dict(checkpoint["model_state_dict"])

    def output_mapping(
        self, outputs: torch.Tensor, match_matrix: torch.Tensor
    ) -> torch.Tensor:
        """Orders the outputs based on the match matrix.

        Args:
            outputs (torch.Tensor): The set of outputs generated by the decoder.
            match_matrix (torch.Tensor):  A 2-D binary matrix, where 1
                represents a match and 0 otherwise.
                Has the same dimensions as the cost matrix.
        Returns:
            torch.Tensor: Outputs ordered in correspondence with inputs.
        """
        return (match_matrix[..., None] * outputs[None, ...]).sum(dim=1)

    def forward(
        self, inputs: torch.Tensor, stacked_outputs: torch.Tensor,
        member_probabilities: torch.Tensor
    ) -> Tuple:
        """Computes cost matrix and performs a matching between inputs and outputs.

        Args:
            inputs (torch.Tensor): Input tensor of shape
                [batch_size x sequence_length x input_size].
            stacked_outputs (torch.Tensor): Reconstructed elements from the
                decoder with shape [batch_size, max_length, input_size].
            member_probabilities (torch.Tensor): Probabilities describing the
                likelihood of elements belonging to the set.
            batch_lengths (torch.Tensor): Actual set lengths of each set in the
                batch.
            max_length (int): The largest set length to which all other sets are
                padded to in the batch.
            
        Returns:
            Tuple: Tuple of the outputs and their membership probabilities
                reordered with respect to the input.
        """

        in_batch_size, input_length, input_size = inputs.size()
        out_batch_size, output_length, output_size = stacked_outputs.size()
        mapped_outputs = []

        with torch.no_grad():

            connector_ = self.connector.expand(in_batch_size, -1, -1)

            x = torch.cat((inputs, connector_, stacked_outputs), dim=1).to(self.device)

            self.mapper.eval()

            if self.model == 'seq2seq':
                test_output, _ = self.mapper(
                    x.permute(1, 0, 2), inputs.permute(1, 0, 2)
                )
            else:
                test_output = self.mapper(x)

            if self.batch_first is False:
                test_output = test_output.permute(1, 0, 2)

            assignments12 = torch.argmax(test_output, 2)

            match_matrices = F.one_hot(assignments12, input_length).float()

        mapped_outputs = list(map(self.output_mapping, stacked_outputs, match_matrices))

        mapped_prob = list(
            map(self.output_mapping, member_probabilities, match_matrices)
        )

        return torch.stack(mapped_outputs), torch.stack(mapped_prob), assignments12
